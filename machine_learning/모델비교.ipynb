{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045019e5-d045-4c10-ab55-d8ab89edcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0123b9ae-dec7-4852-886b-ed7d9e1def0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\python.exe\n",
      "Name: pytorch-tabnet\n",
      "Version: 4.1.0\n",
      "Summary: PyTorch implementation of TabNet\n",
      "Home-page: https://github.com/dreamquark-ai/tabnet\n",
      "Author: \n",
      "Author-email: \n",
      "License: \n",
      "Location: C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\n",
      "Requires: numpy, scikit_learn, scipy, torch, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "!pip show pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29be9564-a238-4b1a-8e3e-e5f4f74d2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnet\n",
      "  Using cached pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.5.1)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (2.6.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (4.66.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
      "Using cached pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pytorch-tabnet\n",
      "Successfully installed pytorch-tabnet-4.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cede785-ae63-4138-b11f-0c7976b779ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# ì „ì²´ ì‹œë“œ ê³ ì • ì½”ë“œ (í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ë©´ ë¨)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # GPUì—ì„œë„ ê³ ì •\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c93dd7ef-25b6-4ce8-91ea-57aa53446610",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized\n"
     ]
    }
   ],
   "source": [
    "# âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ 3ì¢… ì„±ëŠ¥ ë¹„êµ (PyTorch MLP, TabNet, FT-Transformer)\n",
    "\n",
    "\n",
    "\n",
    "# âœ… 1. PyTorch ê¸°ë°˜ MLP ëª¨ë¸ ì •ì˜\n",
    "class FeatureWeightedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_dim = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_dim, dim))  # ê° hidden layer ì¶”ê°€\n",
    "            prev_dim = dim\n",
    "        self.output_layer = nn.Linear(prev_dim, 1)  # ì¶œë ¥ì¸µ\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))  # í™œì„±í™” í•¨ìˆ˜ ì ìš©\n",
    "            if self.dropout_rate > 0:\n",
    "                x = F.dropout(x, p=self.dropout_rate, training=self.training)  # ë“œë¡­ì•„ì›ƒ ì ìš©\n",
    "        x = torch.sigmoid(self.output_layer(x))  # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œê·¸ëª¨ì´ë“œ ì¶œë ¥\n",
    "        return x\n",
    "\n",
    "\n",
    "# âœ… 1-1. MLP í•™ìŠµ ë° êµì°¨ê²€ì¦ í‰ê°€ í•¨ìˆ˜\n",
    "\n",
    "def train_evaluate_pytorch_mlp(X, y, folds=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # ì •ê·œí™”\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        # í…ì„œ ë³€í™˜\n",
    "        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
    "        y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "\n",
    "        model = FeatureWeightedMLP(input_dim=X.shape[1]).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.BCELoss()  # ì´ì§„ ë¶„ë¥˜ìš© loss\n",
    "\n",
    "        # ì—í­ ë°˜ë³µ\n",
    "        for epoch in range(100):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_train_tensor).squeeze()\n",
    "            loss = criterion(preds, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ê²€ì¦\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_val_tensor).squeeze().cpu().numpy()\n",
    "        roc_list.append(roc_auc_score(y_val, preds))\n",
    "        pr_list.append(average_precision_score(y_val, preds))\n",
    "\n",
    "    return np.mean(roc_list), np.mean(pr_list)\n",
    "\n",
    "\n",
    "# âœ… 2. TabNet ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "\n",
    "def train_evaluate_tabnet(X, y, folds=5):\n",
    "    X_np = X.values\n",
    "    y_np = y.values.reshape(-1, 1)\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_np, y_np):\n",
    "        X_train, X_val = X_np[train_idx], X_np[val_idx]\n",
    "        y_train, y_val = y_np[train_idx], y_np[val_idx]\n",
    "        y_train, y_val = y_train.reshape(-1), y_val.reshape(-1)\n",
    "        model = TabNetClassifier(verbose=0)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=['auc'],\n",
    "                  max_epochs=100, patience=20)\n",
    "\n",
    "        preds = model.predict_proba(X_val)[:, 1]  # í´ë˜ìŠ¤ 1ì˜ í™•ë¥ \n",
    "        roc_list.append(roc_auc_score(y_val, preds))\n",
    "        pr_list.append(average_precision_score(y_val, preds))\n",
    "\n",
    "    return np.mean(roc_list), np.mean(pr_list)\n",
    "\n",
    "\n",
    "# âœ… 3. FT-Transformer (ì„ì‹œ ëŒ€ì²´: LogisticRegression ì‚¬ìš©)\n",
    "def train_evaluate_ft_transformer(X, y, folds=5):\n",
    "    from sklearn.linear_model import LogisticRegression  # ì‹¤ì œ FTTransformer ëŒ€ì²´ìš©\n",
    "    roc_list, pr_list = [], []\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=1000)  # ë‹¨ìˆœ ì„ í˜• ëª¨ë¸ë¡œ ëŒ€ì²´\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        preds = clf.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "        roc_list.append(roc_auc_score(y_val, preds))\n",
    "        pr_list.append(average_precision_score(y_val, preds))\n",
    "\n",
    "    return np.mean(roc_list), np.mean(pr_list)\n",
    "\n",
    "\n",
    "# âœ… 4. í†µí•© ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜\n",
    "\n",
    "def compare_all_models(X, y):\n",
    "    print(\"\\nğŸ“Š Comparing PyTorch MLP...\")\n",
    "    mlp_roc, mlp_pr = train_evaluate_pytorch_mlp(X, y)\n",
    "    print(f\"MLP â†’ ROC AUC: {mlp_roc:.4f}, PR AUC: {mlp_pr:.4f}\")\n",
    "\n",
    "    print(\"\\nğŸ“Š Comparing TabNet (PyTorch)...\")\n",
    "    tabnet_roc, tabnet_pr = train_evaluate_tabnet(X, y)\n",
    "    print(f\"TabNet â†’ ROC AUC: {tabnet_roc:.4f}, PR AUC: {tabnet_pr:.4f}\")\n",
    "\n",
    "    print(\"\\nğŸ“Š Comparing FT-Transformer (Simulated)...\")\n",
    "    ft_roc, ft_pr = train_evaluate_ft_transformer(X, y)\n",
    "    print(f\"FT-Transformer â†’ ROC AUC: {ft_roc:.4f}, PR AUC: {ft_pr:.4f}\")\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "    print(\"\\nâœ… Summary\")\n",
    "    print(f\"PyTorch MLP     : ROC AUC = {mlp_roc:.4f}, PR AUC = {mlp_pr:.4f}\")\n",
    "    print(f\"TabNet          : ROC AUC = {tabnet_roc:.4f}, PR AUC = {tabnet_pr:.4f}\")\n",
    "    print(f\"FT-Transformer  : ROC AUC = {ft_roc:.4f}, PR AUC = {ft_pr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201f0aaa-135b-40c5-af95-6edd41027613",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/(ìµœì¢…)_ì„œìš¸ì—´ì„ _ê´‘ì§„ë„ë¡œ.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124më„ë¡œ ì¢…ë¥˜\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124më„ë¡œí­\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mê²½ì‚¬ê°\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mìµœê·¼ì ‘_ì‹œì„¤ì˜_í‰ê· ê±°ë¦¬\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì¢…í•©_í‰ê· _ê¸°ì˜¨\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mìƒí™œì¸êµ¬\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mìµœê·¼ì ‘_ì‹œì„¤ë“¤_ìµœì†Œê±°ë¦¬\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mìµœê·¼ì ‘_ì‹œì„¤ë“¤_ìµœëŒ€ê±°ë¦¬\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì—´ì„ \u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('data/(ìµœì¢…)_ì„œìš¸ì—´ì„ _ê´‘ì§„ë„ë¡œ.csv')\n",
    "X = pd.get_dummies(data[['ë„ë¡œ ì¢…ë¥˜', 'ë„ë¡œí­', 'ê²½ì‚¬ê°', 'ìµœê·¼ì ‘_ì‹œì„¤ì˜_í‰ê· ê±°ë¦¬', 'ì¢…í•©_í‰ê· _ê¸°ì˜¨', 'ìƒí™œì¸êµ¬', 'ìµœê·¼ì ‘_ì‹œì„¤ë“¤_ìµœì†Œê±°ë¦¬', 'ìµœê·¼ì ‘_ì‹œì„¤ë“¤_ìµœëŒ€ê±°ë¦¬']])\n",
    "y = data['ì—´ì„ ']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "\n",
    "compare_all_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d57a6f-7928-4f74-a192-142525ebfd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5727, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79757040-0ebd-42ca-8c54-7f34778bdaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8005\n",
      "\n",
      "Gradients before update:\n",
      "0.weight grad:\n",
      "tensor([[ 0.0261, -0.0154,  0.0210],\n",
      "        [ 0.0363, -0.0241,  0.0322],\n",
      "        [-0.0589, -0.0133, -0.0261],\n",
      "        [-0.0453,  0.1042, -0.0556],\n",
      "        [ 0.0041, -0.0320,  0.0046]])\n",
      "0.bias grad:\n",
      "tensor([ 0.0090,  0.0168,  0.0425, -0.0613,  0.0153])\n",
      "2.weight grad:\n",
      "tensor([[-0.0022, -0.0223, -0.1134, -0.0328, -0.1020]])\n",
      "2.bias grad:\n",
      "tensor([-0.3158])\n",
      "\n",
      "Weights after update:\n",
      "0.weight:\n",
      "tensor([[ 0.5429,  0.1643, -0.3049],\n",
      "        [ 0.4136, -0.1097, -0.3877],\n",
      "        [-0.4631, -0.2633,  0.2436],\n",
      "        [ 0.1357, -0.1871, -0.1949],\n",
      "        [-0.1461, -0.3870,  0.5336]])\n",
      "0.bias:\n",
      "tensor([-0.5135, -0.0686,  0.0749,  0.0087, -0.0268])\n",
      "2.weight:\n",
      "tensor([[-0.3546, -0.1918, -0.2372,  0.4107, -0.1262]])\n",
      "2.bias:\n",
      "tensor([-0.2895])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. ë”ë¯¸ ë°ì´í„° ìƒì„± (10ê°œ ìƒ˜í”Œ, 3ê°œ íŠ¹ì„±)\n",
    "X = torch.randn(10, 3)\n",
    "y = torch.randint(0, 2, (10,)).float()\n",
    "\n",
    "# 2. ë‹¨ìˆœí•œ MLP ëª¨ë¸ (ì…ë ¥ 3 â†’ ì€ë‹‰ì¸µ 5 â†’ ì¶œë ¥ 1)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# 3. ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 4. Forward pass: ì˜ˆì¸¡\n",
    "y_pred = model(X).squeeze()\n",
    "\n",
    "# 5. ì†ì‹¤ ê³„ì‚°\n",
    "loss = criterion(y_pred, y)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 6. ì—­ì „íŒŒ: gradient ê³„ì‚°\n",
    "loss.backward()\n",
    "\n",
    "# 7. ê° ë ˆì´ì–´ì˜ gradient ì¶œë ¥ (before update)\n",
    "print(\"\\nGradients before update:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} grad:\\n{param.grad}\")\n",
    "\n",
    "# 8. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "optimizer.step()\n",
    "\n",
    "# 9. ì—…ë°ì´íŠ¸ í›„ ê°€ì¤‘ì¹˜ í™•ì¸\n",
    "print(\"\\nWeights after update:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}:\\n{param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf9c0a-6d1b-4368-be8e-4292a87e9471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba13b12-1e17-4c35-8e8a-6bec8e46ab70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
