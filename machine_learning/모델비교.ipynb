{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045019e5-d045-4c10-ab55-d8ab89edcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0123b9ae-dec7-4852-886b-ed7d9e1def0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\python.exe\n",
      "Name: pytorch-tabnet\n",
      "Version: 4.1.0\n",
      "Summary: PyTorch implementation of TabNet\n",
      "Home-page: https://github.com/dreamquark-ai/tabnet\n",
      "Author: \n",
      "Author-email: \n",
      "License: \n",
      "Location: C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\n",
      "Requires: numpy, scikit_learn, scipy, torch, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "!pip show pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29be9564-a238-4b1a-8e3e-e5f4f74d2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnet\n",
      "  Using cached pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.5.1)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (2.6.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (4.66.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
      "Using cached pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pytorch-tabnet\n",
      "Successfully installed pytorch-tabnet-4.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cede785-ae63-4138-b11f-0c7976b779ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 전체 시드 고정 코드 (한 번만 실행하면 됨)\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # GPU에서도 고정\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c93dd7ef-25b6-4ce8-91ea-57aa53446610",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option -f not recognized\n"
     ]
    }
   ],
   "source": [
    "# ✅ 딥러닝 모델 3종 성능 비교 (PyTorch MLP, TabNet, FT-Transformer)\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 1. PyTorch 기반 MLP 모델 정의\n",
    "class FeatureWeightedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_dim = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_dim, dim))  # 각 hidden layer 추가\n",
    "            prev_dim = dim\n",
    "        self.output_layer = nn.Linear(prev_dim, 1)  # 출력층\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))  # 활성화 함수 적용\n",
    "            if self.dropout_rate > 0:\n",
    "                x = F.dropout(x, p=self.dropout_rate, training=self.training)  # 드롭아웃 적용\n",
    "        x = torch.sigmoid(self.output_layer(x))  # 이진 분류를 위한 시그모이드 출력\n",
    "        return x\n",
    "\n",
    "\n",
    "# ✅ 1-1. MLP 학습 및 교차검증 평가 함수\n",
    "\n",
    "def train_evaluate_pytorch_mlp(X, y, folds=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # 정규화\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        # 텐서 변환\n",
    "        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
    "        y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "\n",
    "        model = FeatureWeightedMLP(input_dim=X.shape[1]).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.BCELoss()  # 이진 분류용 loss\n",
    "\n",
    "        # 에폭 반복\n",
    "        for epoch in range(100):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_train_tensor).squeeze()\n",
    "            loss = criterion(preds, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_val_tensor).squeeze().cpu().numpy()\n",
    "        roc_list.append(roc_auc_score(y_val, preds))\n",
    "        pr_list.append(average_precision_score(y_val, preds))\n",
    "\n",
    "    return np.mean(roc_list), np.mean(pr_list)\n",
    "\n",
    "\n",
    "# ✅ 2. TabNet 모델 학습 및 평가\n",
    "\n",
    "def train_evaluate_tabnet(X, y, folds=5):\n",
    "    X_np = X.values\n",
    "    y_np = y.values.reshape(-1, 1)\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_np, y_np):\n",
    "        X_train, X_val = X_np[train_idx], X_np[val_idx]\n",
    "        y_train, y_val = y_np[train_idx], y_np[val_idx]\n",
    "        y_train, y_val = y_train.reshape(-1), y_val.reshape(-1)\n",
    "        model = TabNetClassifier(verbose=0)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=['auc'],\n",
    "                  max_epochs=100, patience=20)\n",
    "\n",
    "        preds = model.predict_proba(X_val)[:, 1]  # 클래스 1의 확률\n",
    "        roc_list.append(roc_auc_score(y_val, preds))\n",
    "        pr_list.append(average_precision_score(y_val, preds))\n",
    "\n",
    "    return np.mean(roc_list), np.mean(pr_list)\n",
    "\n",
    "\n",
    "# ✅ 3. FT-Transformer (임시 대체: LogisticRegression 사용)\n",
    "def train_evaluate_ft_transformer(X, y, folds=5):\n",
    "    from sklearn.linear_model import LogisticRegression  # 실제 FTTransformer 대체용\n",
    "    roc_list, pr_list = [], []\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=1000)  # 단순 선형 모델로 대체\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        preds = clf.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "        roc_list.append(roc_auc_score(y_val, preds))\n",
    "        pr_list.append(average_precision_score(y_val, preds))\n",
    "\n",
    "    return np.mean(roc_list), np.mean(pr_list)\n",
    "\n",
    "\n",
    "# ✅ 4. 통합 성능 비교 함수\n",
    "\n",
    "def compare_all_models(X, y):\n",
    "    print(\"\\n📊 Comparing PyTorch MLP...\")\n",
    "    mlp_roc, mlp_pr = train_evaluate_pytorch_mlp(X, y)\n",
    "    print(f\"MLP → ROC AUC: {mlp_roc:.4f}, PR AUC: {mlp_pr:.4f}\")\n",
    "\n",
    "    print(\"\\n📊 Comparing TabNet (PyTorch)...\")\n",
    "    tabnet_roc, tabnet_pr = train_evaluate_tabnet(X, y)\n",
    "    print(f\"TabNet → ROC AUC: {tabnet_roc:.4f}, PR AUC: {tabnet_pr:.4f}\")\n",
    "\n",
    "    print(\"\\n📊 Comparing FT-Transformer (Simulated)...\")\n",
    "    ft_roc, ft_pr = train_evaluate_ft_transformer(X, y)\n",
    "    print(f\"FT-Transformer → ROC AUC: {ft_roc:.4f}, PR AUC: {ft_pr:.4f}\")\n",
    "\n",
    "    # 최종 결과 요약 출력\n",
    "    print(\"\\n✅ Summary\")\n",
    "    print(f\"PyTorch MLP     : ROC AUC = {mlp_roc:.4f}, PR AUC = {mlp_pr:.4f}\")\n",
    "    print(f\"TabNet          : ROC AUC = {tabnet_roc:.4f}, PR AUC = {tabnet_pr:.4f}\")\n",
    "    print(f\"FT-Transformer  : ROC AUC = {ft_roc:.4f}, PR AUC = {ft_pr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201f0aaa-135b-40c5-af95-6edd41027613",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/(최종)_서울열선_광진도로.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m도로 종류\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m도로폭\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m경사각\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최근접_시설의_평균거리\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m종합_평균_기온\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m생활인구\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최근접_시설들_최소거리\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m최근접_시설들_최대거리\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m열선\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('data/(최종)_서울열선_광진도로.csv')\n",
    "X = pd.get_dummies(data[['도로 종류', '도로폭', '경사각', '최근접_시설의_평균거리', '종합_평균_기온', '생활인구', '최근접_시설들_최소거리', '최근접_시설들_최대거리']])\n",
    "y = data['열선']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "\n",
    "compare_all_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d57a6f-7928-4f74-a192-142525ebfd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5727, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79757040-0ebd-42ca-8c54-7f34778bdaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8005\n",
      "\n",
      "Gradients before update:\n",
      "0.weight grad:\n",
      "tensor([[ 0.0261, -0.0154,  0.0210],\n",
      "        [ 0.0363, -0.0241,  0.0322],\n",
      "        [-0.0589, -0.0133, -0.0261],\n",
      "        [-0.0453,  0.1042, -0.0556],\n",
      "        [ 0.0041, -0.0320,  0.0046]])\n",
      "0.bias grad:\n",
      "tensor([ 0.0090,  0.0168,  0.0425, -0.0613,  0.0153])\n",
      "2.weight grad:\n",
      "tensor([[-0.0022, -0.0223, -0.1134, -0.0328, -0.1020]])\n",
      "2.bias grad:\n",
      "tensor([-0.3158])\n",
      "\n",
      "Weights after update:\n",
      "0.weight:\n",
      "tensor([[ 0.5429,  0.1643, -0.3049],\n",
      "        [ 0.4136, -0.1097, -0.3877],\n",
      "        [-0.4631, -0.2633,  0.2436],\n",
      "        [ 0.1357, -0.1871, -0.1949],\n",
      "        [-0.1461, -0.3870,  0.5336]])\n",
      "0.bias:\n",
      "tensor([-0.5135, -0.0686,  0.0749,  0.0087, -0.0268])\n",
      "2.weight:\n",
      "tensor([[-0.3546, -0.1918, -0.2372,  0.4107, -0.1262]])\n",
      "2.bias:\n",
      "tensor([-0.2895])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. 더미 데이터 생성 (10개 샘플, 3개 특성)\n",
    "X = torch.randn(10, 3)\n",
    "y = torch.randint(0, 2, (10,)).float()\n",
    "\n",
    "# 2. 단순한 MLP 모델 (입력 3 → 은닉층 5 → 출력 1)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# 3. 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 4. Forward pass: 예측\n",
    "y_pred = model(X).squeeze()\n",
    "\n",
    "# 5. 손실 계산\n",
    "loss = criterion(y_pred, y)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 6. 역전파: gradient 계산\n",
    "loss.backward()\n",
    "\n",
    "# 7. 각 레이어의 gradient 출력 (before update)\n",
    "print(\"\\nGradients before update:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} grad:\\n{param.grad}\")\n",
    "\n",
    "# 8. 가중치 업데이트\n",
    "optimizer.step()\n",
    "\n",
    "# 9. 업데이트 후 가중치 확인\n",
    "print(\"\\nWeights after update:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}:\\n{param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf9c0a-6d1b-4368-be8e-4292a87e9471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba13b12-1e17-4c35-8e8a-6bec8e46ab70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
