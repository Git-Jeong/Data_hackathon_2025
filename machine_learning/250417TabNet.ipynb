{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad6a900-da44-4d4b-af2a-83647a0cd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ TabNetClassifier 기반의 모델 학습 및 평가 함수들 (pytorch-tabnet 사용)\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 확인용\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "60664b81-6025-4b19-9297-4e7550ca3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ TabNetClassifier 학습 함수\n",
    "# 하이퍼파라미터(tabnet_params)와 수동 가중치(manual_weights)를 포함해 모델을 학습하고, validation 성능 기준으로 조기 종료\n",
    "\n",
    "def train_tabnet_classifier(X_train, y_train, X_val, y_val,\n",
    "                             manual_weights=None,\n",
    "                             tabnet_params=None,\n",
    "                             max_epochs=100, patience=10,\n",
    "                             batch_size=512, device_name='auto'):\n",
    "    device_name = 'cuda' if torch.cuda.is_available() else 'auto'\n",
    "    # tabnet_params가 None이면 빈 딕셔너리로 초기화\n",
    "    if tabnet_params is None:\n",
    "        tabnet_params = {}\n",
    "\n",
    "    # ✅ 입력 데이터 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    # TabNetClassifier 인스턴스 생성 (기본 파라미터 + 추가 하이퍼파라미터)\n",
    "    clf = TabNetClassifier(\n",
    "        seed=42,  # 재현성을 위한 시드 고정\n",
    "        verbose=0,  # 학습 중 로그 출력 레벨\n",
    "        device_name=device_name,  # 'auto'이면 가능한 경우 GPU 사용\n",
    "        **tabnet_params  # 사용자 정의 하이퍼파라미터 적용\n",
    "    )\n",
    "\n",
    "    # 필요시 수동 가중치 적용\n",
    "    if manual_weights is not None:\n",
    "        clf.manual_weights = manual_weights  # 수동 가중치 기능 커스텀 시 활용\n",
    "\n",
    "    # 모델 학습\n",
    "    clf.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],  # 검증 데이터로 평가\n",
    "        eval_metric=['auc', 'logloss'],  # 평가 지표\n",
    "        max_epochs=max_epochs,  # 최대 에폭 수\n",
    "        patience=patience,  # 조기 종료 기준\n",
    "        batch_size=batch_size,  # 배치 사이즈 설정\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "\n",
    "# ✅ TabNetClassifier 평가 함수\n",
    "# ROC AUC 및 PR AUC(정밀도-재현율 곡선) 계산\n",
    "\n",
    "def evaluate_tabnet_classifier(clf, X, y):\n",
    "    # ✅ 입력 데이터 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    preds = clf.predict_proba(X)[:, 1]  # 긍정 클래스 확률 예측\n",
    "    roc = roc_auc_score(y, preds)       # ROC AUC 계산\n",
    "    pr = average_precision_score(y, preds)  # PR AUC 계산\n",
    "    return roc, pr\n",
    "\n",
    "\n",
    "# ✅ TabNetClassifier 기반 교차검증 함수\n",
    "# 지정된 수동 가중치(manual_weights)와 TabNet 하이퍼파라미터(tabnet_params)를 사용하여 K겹 교차검증 수행\n",
    "\n",
    "def cross_validate_tabnet_classifier(X, y,\n",
    "                                     manual_weights=None,\n",
    "                                     tabnet_params=None,\n",
    "                                     k=5,\n",
    "                                     max_epochs=200,\n",
    "                                     patience=30,\n",
    "                                     batch_size=512,\n",
    "                                     device_name='auto'):\n",
    "    \n",
    "    # Stratified K-Fold를 사용하여 클래스 비율 유지\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []  # 점수 저장 리스트\n",
    "    \n",
    "    # 각 fold에 대해 반복 수행\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        # fold마다 동일한 하이퍼파라미터로 모델 학습\n",
    "        clf = train_tabnet_classifier(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            manual_weights=manual_weights,\n",
    "            tabnet_params=tabnet_params,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        # 모델 평가 및 점수 저장\n",
    "        roc, pr = evaluate_tabnet_classifier(clf, X_val, y_val)\n",
    "        roc_list.append(roc)\n",
    "        pr_list.append(pr)\n",
    "\n",
    "    # 평균 및 표준편차 출력\n",
    "    print(f\"ROC AUC (mean ± std): {np.mean(roc_list):.4f} ± {np.std(roc_list):.4f}\")\n",
    "    print(f\"PR  AUC (mean ± std): {np.mean(pr_list):.4f} ± {np.std(pr_list):.4f}\")\n",
    "    return roc_list, pr_list\n",
    "\n",
    "\n",
    "# ✅ TabNetClassifier용 랜덤 서치 함수\n",
    "# PR AUC를 기준으로 하이퍼파라미터 조합 중 상위 5개를 출력하고, 최고 조합 반환\n",
    "\n",
    "def random_search_tabnet(X, y, param_dist, n_iter=10, k=3,\n",
    "                          max_epochs=300, patience=50,\n",
    "                          batch_size=512, device_name='auto'):\n",
    "    results = []  # (ROC AUC, PR AUC, 하이퍼파라미터) 튜플 리스트\n",
    "    \n",
    "    # 하이퍼파라미터 랜덤 샘플링 반복\n",
    "    for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=None):\n",
    "        # n_d == n_a로 강제 동기화\n",
    "        if 'n_d' in params:\n",
    "            params['n_a'] = params['n_d']\n",
    "\n",
    "        print(f\"Testing params: {params}\")\n",
    "\n",
    "        # TabNetClassifier에 적용할 파라미터만 필터링\n",
    "        tabnet_keys = [\n",
    "            \"n_d\", \"n_a\", \"n_steps\", \"gamma\",\n",
    "            \"lambda_sparse\", \"optimizer_params\",\n",
    "            \"virtual_batch_size\", \"momentum\"\n",
    "        ]\n",
    "        tabnet_params = {k: params[k] for k in tabnet_keys if k in params}\n",
    "\n",
    "        # 교차검증 수행하여 PR AUC 측정\n",
    "        roc_scores, pr_scores = cross_validate_tabnet_classifier(\n",
    "            X, y,\n",
    "            manual_weights=params.get(\"manual_weights\", None),\n",
    "            tabnet_params=tabnet_params,\n",
    "            k=k,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        mean_pr = np.mean(pr_scores)  # PR AUC 평균\n",
    "        mean_roc = np.mean(roc_scores)  # ROC AUC 평균\n",
    "        results.append((mean_pr, mean_roc, params))\n",
    "\n",
    "    # PR AUC 기준 상위 5개 하이퍼파라미터 조합 출력\n",
    "    results.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_results = results[:5]\n",
    "\n",
    "    print(\"\\nTop 5 PR AUC results:\")\n",
    "    for i, (pr_score, roc_score, params) in enumerate(top_results, 1):\n",
    "        print(f\"{i}. ROC AUC = {roc_score:.4f}, PR AUC = {pr_score:.4f} with params: {params}\")\n",
    "\n",
    "    best_pr, best_roc, best_params = top_results[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96b4b96-1800-45e7-bf13-35d5498d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ TabNetClassifier 기반의 모델 학습 및 평가 함수들 (DataFrame 친화 버전)\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# ✅ TabNetClassifier 학습 함수 (DataFrame 버전)\n",
    "def train_tabnet_classifier_df(X_train, y_train, X_val, y_val,\n",
    "                                manual_weights=None,\n",
    "                                tabnet_params=None,\n",
    "                                max_epochs=100, patience=10,\n",
    "                                batch_size=1024, device_name='auto'):\n",
    "    if tabnet_params is None:\n",
    "        tabnet_params = {}\n",
    "\n",
    "    # ✅ 입력 데이터 스케일링 (DataFrame 유지)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "\n",
    "    clf = TabNetClassifier(\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        device_name=device_name,\n",
    "        **tabnet_params\n",
    "    )\n",
    "\n",
    "    if manual_weights is not None:\n",
    "        clf.manual_weights = manual_weights\n",
    "\n",
    "    clf.fit(\n",
    "        X_train=X_train_scaled.values, y_train=y_train.values,\n",
    "        eval_set=[(X_val_scaled.values, y_val.values)],\n",
    "        eval_metric=['auc', 'logloss'],\n",
    "        max_epochs=max_epochs,\n",
    "        patience=patience,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return clf, scaler\n",
    "\n",
    "# ✅ TabNetClassifier 평가 함수 (DataFrame 버전)\n",
    "def evaluate_tabnet_classifier_df(clf, X, y, scaler):\n",
    "    # 입력 데이터를 학습 시 사용한 스케일러로 변환 (DataFrame 유지)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    preds = clf.predict_proba(X_scaled.values)[:, 1]  # 긍정 클래스 확률 예측\n",
    "    roc = roc_auc_score(y, preds)       # ROC AUC 계산\n",
    "    pr = average_precision_score(y, preds)  # PR AUC 계산\n",
    "    return roc, pr\n",
    "\n",
    "# ✅ 교차검증 함수\n",
    "\n",
    "def cross_validate_tabnet_classifier_df(X, y,\n",
    "                                        manual_weights=None,\n",
    "                                        tabnet_params=None,\n",
    "                                        k=5,\n",
    "                                        max_epochs=200,\n",
    "                                        patience=30,\n",
    "                                        batch_size=1024,\n",
    "                                        device_name='auto'):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X.values, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        clf, scaler = train_tabnet_classifier_df(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            manual_weights=manual_weights,\n",
    "            tabnet_params=tabnet_params,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        roc, pr = evaluate_tabnet_classifier_df(clf, X_val, y_val, scaler)\n",
    "        roc_list.append(roc)\n",
    "        pr_list.append(pr)\n",
    "\n",
    "    print(f\"ROC AUC (mean ± std): {np.mean(roc_list):.4f} ± {np.std(roc_list):.4f}\")\n",
    "    print(f\"PR  AUC (mean ± std): {np.mean(pr_list):.4f} ± {np.std(pr_list):.4f}\")\n",
    "    return roc_list, pr_list\n",
    "\n",
    "# ✅ 랜덤서치 함수\n",
    "\n",
    "def random_search_tabnet_df(X, y, param_dist, n_iter=10, k=3,\n",
    "                             max_epochs=100, patience=10,\n",
    "                             batch_size=1024, device_name='auto'):\n",
    "    results = []\n",
    "\n",
    "    for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=None):\n",
    "        # n_d == n_a로 강제 동기화\n",
    "        if 'n_d' in params:\n",
    "            params['n_a'] = params['n_d']\n",
    "        print(f\"Testing params: {params}\")\n",
    "\n",
    "        tabnet_keys = [\n",
    "            \"n_d\", \"n_a\", \"n_steps\", \"gamma\",\n",
    "            \"lambda_sparse\", \"optimizer_params\",\n",
    "            \"virtual_batch_size\", \"momentum\"\n",
    "        ]\n",
    "        tabnet_params = {k: params[k] for k in tabnet_keys if k in params}\n",
    "\n",
    "        roc_scores, pr_scores = cross_validate_tabnet_classifier_df(\n",
    "            X, y,\n",
    "            manual_weights=params.get(\"manual_weights\", None),\n",
    "            tabnet_params=tabnet_params,\n",
    "            k=k,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        mean_roc = np.mean(roc_scores)\n",
    "        mean_pr = np.mean(pr_scores)\n",
    "        results.append((mean_pr, mean_roc, params))\n",
    "\n",
    "    results.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_results = results[:5]\n",
    "\n",
    "    print(\"\\nTop 5 PR AUC results:\")\n",
    "    for i, (pr_score, roc_score, params) in enumerate(top_results, 1):\n",
    "        print(f\"{i}. ROC AUC = {roc_score:.4f}, PR AUC = {pr_score:.4f} with params: {params}\")\n",
    "\n",
    "    best_pr, best_roc, best_params = top_results[0]\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5cd951-2c7c-402c-9b10-eba3591a6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. 시드 고정 함수 정의\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # multi-GPU 사용 시\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ✅ 2. 시드 고정\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775045b-6db3-43d9-b0fd-df90c0362ce4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ✅ TabNet 예시 코드 (작동 확인용)\n",
    "\n",
    "# ✅ 1. 더미 데이터 생성 (이진 분류용)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20,\n",
    "    n_informative=10, n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 2. train/test 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ✅ 3. TabNetClassifier 초기화 및 학습\n",
    "clf = TabNetClassifier(\n",
    "    seed=42,\n",
    "    verbose=0,\n",
    "    device_name='auto'  # GPU 사용 가능하면 자동 감지\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# ✅ 4. 예측 및 평가\n",
    "preds_proba = clf.predict_proba(X_test)[:, 1]\n",
    "preds_label = clf.predict(X_test)\n",
    "\n",
    "# ✅ 5. 성능 출력\n",
    "roc = roc_auc_score(y_test, preds_proba)\n",
    "acc = accuracy_score(y_test, preds_label)\n",
    "\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87fb7d04-3680-4d95-88bf-ba8db68617dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 도로 데이터 불러오기\n",
    "data = pd.read_csv('data/(최종)_서울열선_광진도로.csv')\n",
    "X = pd.get_dummies(data[['도로 종류', '도로폭', '경사각', '최근접_시설의_평균거리', '종합_평균_기온', '생활인구', '최근접_시설들_최소거리', '최근접_시설들_최대거리']])\n",
    "y = data['열선']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "X = X.astype('float')\n",
    "# 💡 인덱스 초기화 (안 하면 batch_size가 전체인 경우 오류 발생 가능)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e93aa2d-73bd-406a-9579-9888649a6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    # 표현 차원 (표현력 증가에 영향을 줌)\n",
    "    \"n_d\": 64,\n",
    "    \"n_a\": 64,  # 일반적으로 n_d와 같은 값을 사용\n",
    "    # 모델 깊이 (더 깊으면 복잡도 증가, 학습 시간 증가)\n",
    "    \"n_steps\": 3,\n",
    "    # 희소성 관련 하이퍼파라미터 (특성 선택을 얼마나 강하게 할지)\n",
    "    \"gamma\": 2.0,\n",
    "    \"lambda_sparse\": 0.15,\n",
    "    # 옵티마이저 학습률\n",
    "    \"optimizer_params\": dict(lr=0.001)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef17e0fc-70e8-49a4-848d-f0618bf3f139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 500 with best_epoch = 474 and best_val_0_logloss = 0.17709\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC: 0.9402\n",
      "PR  AUC: 0.8579\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 190 and best_val_0_logloss = 0.21651\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 196 and best_val_0_logloss = 0.20004\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 149 and best_val_0_logloss = 0.23165\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 172 with best_epoch = 112 and best_val_0_logloss = 0.1998\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 185 and best_val_0_logloss = 0.21332\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean ± std): 0.9198 ± 0.0104\n",
      "PR  AUC (mean ± std): 0.7933 ± 0.0218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.917670902716915,\n",
       "  0.9325007721984339,\n",
       "  0.9088652093385974,\n",
       "  0.9312399473607254,\n",
       "  0.908533167617098],\n",
       " [0.7792528661717667,\n",
       "  0.819999157915361,\n",
       "  0.759417458367711,\n",
       "  0.8105622880393578,\n",
       "  0.7974581902997006])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ 3. TabNetClassifier 초기화 및 학습\n",
    "model, scaler = train_tabnet_classifier_df(X_train=X_train, y_train=y_train, X_val=X_test, y_val=y_test,patience=250, max_epochs=500, tabnet_params=param_dist)\n",
    "\n",
    "# ✅ 4. 예측 및 평가\n",
    "roc, pr = evaluate_tabnet_classifier_df(model, X_test, y_test, scaler)\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "print(f\"PR  AUC: {pr:.4f}\")\n",
    "\n",
    "cross_validate_tabnet_classifier_df(X_train, y_train, batch_size=1024, tabnet_params=param_dist, max_epochs=200, patience=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd010a1-25a5-4e6e-81f1-f5ec9f014783",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    # 표현 차원 (표현력 증가에 영향을 줌)\n",
    "    \"n_d\": [32, 64],\n",
    "    \"n_a\": [32, 64],  # 일반적으로 n_d와 같은 값을 사용\n",
    "\n",
    "    # 모델 깊이 (더 깊으면 복잡도 증가, 학습 시간 증가)\n",
    "    \"n_steps\": [3, 4, 5],\n",
    "\n",
    "    # 희소성 관련 하이퍼파라미터 (특성 선택을 얼마나 강하게 할지)\n",
    "    \"gamma\": [1.5, 1.7, 1.8, 2.0],\n",
    "    \"lambda_sparse\": [1e-2, 5e-2, 1e-1],\n",
    "\n",
    "    # 옵티마이저 학습률\n",
    "    \"optimizer_params\": [\n",
    "        dict(lr=0.001),\n",
    "        dict(lr=0.005),\n",
    "        dict(lr=0.01)\n",
    "    ],\n",
    "\n",
    "    # # 가상 배치 사이즈 (BN 안정화 목적)\n",
    "    # \"virtual_batch_size\": [128, 256],\n",
    "\n",
    "    # # Ghost BN 모멘텀\n",
    "    # \"momentum\": [0.02, 0.05],\n",
    "\n",
    "    # 향후 확장용 수동 특성 가중치\n",
    "    \"manual_weights\": [None]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a852732e-5d77-47aa-af07-ca302c544918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.5}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 163 and best_val_0_logloss = 0.20262\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 271 and best_val_0_logloss = 0.20769\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 191 and best_val_0_logloss = 0.20679\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean ± std): 0.9238 ± 0.0048\n",
      "PR  AUC (mean ± std): 0.8092 ± 0.0028\n",
      "Testing params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 195 and best_val_0_logloss = 0.20762\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 288 and best_val_0_logloss = 0.22474\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 291 and best_val_0_logloss = 0.1876\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean ± std): 0.9197 ± 0.0127\n",
      "PR  AUC (mean ± std): 0.8026 ± 0.0285\n",
      "Testing params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 5, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.8}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 299 and best_val_0_logloss = 0.24403\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 203 and best_val_0_logloss = 0.25728\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 277 and best_val_0_logloss = 0.26886\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean ± std): 0.8914 ± 0.0042\n",
      "PR  AUC (mean ± std): 0.6919 ± 0.0272\n",
      "Testing params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.1, 'gamma': 1.5}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 294 and best_val_0_logloss = 0.19203\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 222 and best_val_0_logloss = 0.22913\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 295 and best_val_0_logloss = 0.17797\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean ± std): 0.9243 ± 0.0134\n",
      "PR  AUC (mean ± std): 0.8123 ± 0.0417\n",
      "Testing params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 273 and best_val_0_logloss = 0.24458\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 299 and best_val_0_logloss = 0.25863\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 296 and best_val_0_logloss = 0.27468\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean ± std): 0.8926 ± 0.0061\n",
      "PR  AUC (mean ± std): 0.6901 ± 0.0228\n",
      "\n",
      "Top 5 PR AUC results:\n",
      "1. ROC AUC = 0.9243, PR AUC = 0.8123 with params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.1, 'gamma': 1.5}\n",
      "2. ROC AUC = 0.9238, PR AUC = 0.8092 with params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.5}\n",
      "3. ROC AUC = 0.9197, PR AUC = 0.8026 with params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n",
      "4. ROC AUC = 0.8914, PR AUC = 0.6919 with params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 5, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.8}\n",
      "5. ROC AUC = 0.8926, PR AUC = 0.6901 with params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optimizer_params': {'lr': 0.01},\n",
       " 'n_steps': 4,\n",
       " 'n_d': 32,\n",
       " 'n_a': 32,\n",
       " 'manual_weights': None,\n",
       " 'lambda_sparse': 0.1,\n",
       " 'gamma': 1.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tabnet_df(X_train, y_train, param_dist=param_dist, n_iter=5, k=3, batch_size=X_train.shape[0], max_epochs=300, patience=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b012093-94a3-443a-a45a-33bc4911a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) \n",
    "X_train_scaled = scaler.fit_transform(X_train)   # fit + transform\n",
    "X_val_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469295c1-fc2a-486d-b303-82eca700028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tabnet-39)",
   "language": "python",
   "name": "tabnet-39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
