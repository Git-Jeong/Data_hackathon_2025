{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad6a900-da44-4d4b-af2a-83647a0cd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… TabNetClassifier ê¸°ë°˜ì˜ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ë“¤ (pytorch-tabnet ì‚¬ìš©)\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ì˜ˆì‹œ í™•ì¸ìš©\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "60664b81-6025-4b19-9297-4e7550ca3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… TabNetClassifier í•™ìŠµ í•¨ìˆ˜\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°(tabnet_params)ì™€ ìˆ˜ë™ ê°€ì¤‘ì¹˜(manual_weights)ë¥¼ í¬í•¨í•´ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , validation ì„±ëŠ¥ ê¸°ì¤€ìœ¼ë¡œ ì¡°ê¸° ì¢…ë£Œ\n",
    "\n",
    "def train_tabnet_classifier(X_train, y_train, X_val, y_val,\n",
    "                             manual_weights=None,\n",
    "                             tabnet_params=None,\n",
    "                             max_epochs=100, patience=10,\n",
    "                             batch_size=512, device_name='auto'):\n",
    "    device_name = 'cuda' if torch.cuda.is_available() else 'auto'\n",
    "    # tabnet_paramsê°€ Noneì´ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”\n",
    "    if tabnet_params is None:\n",
    "        tabnet_params = {}\n",
    "\n",
    "    # âœ… ì…ë ¥ ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    # TabNetClassifier ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ê¸°ë³¸ íŒŒë¼ë¯¸í„° + ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°)\n",
    "    clf = TabNetClassifier(\n",
    "        seed=42,  # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •\n",
    "        verbose=0,  # í•™ìŠµ ì¤‘ ë¡œê·¸ ì¶œë ¥ ë ˆë²¨\n",
    "        device_name=device_name,  # 'auto'ì´ë©´ ê°€ëŠ¥í•œ ê²½ìš° GPU ì‚¬ìš©\n",
    "        **tabnet_params  # ì‚¬ìš©ì ì •ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©\n",
    "    )\n",
    "\n",
    "    # í•„ìš”ì‹œ ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    if manual_weights is not None:\n",
    "        clf.manual_weights = manual_weights  # ìˆ˜ë™ ê°€ì¤‘ì¹˜ ê¸°ëŠ¥ ì»¤ìŠ¤í…€ ì‹œ í™œìš©\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    clf.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],  # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
    "        eval_metric=['auc', 'logloss'],  # í‰ê°€ ì§€í‘œ\n",
    "        max_epochs=max_epochs,  # ìµœëŒ€ ì—í­ ìˆ˜\n",
    "        patience=patience,  # ì¡°ê¸° ì¢…ë£Œ ê¸°ì¤€\n",
    "        batch_size=batch_size,  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì •\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "\n",
    "# âœ… TabNetClassifier í‰ê°€ í•¨ìˆ˜\n",
    "# ROC AUC ë° PR AUC(ì •ë°€ë„-ì¬í˜„ìœ¨ ê³¡ì„ ) ê³„ì‚°\n",
    "\n",
    "def evaluate_tabnet_classifier(clf, X, y):\n",
    "    # âœ… ì…ë ¥ ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    preds = clf.predict_proba(X)[:, 1]  # ê¸ì • í´ë˜ìŠ¤ í™•ë¥  ì˜ˆì¸¡\n",
    "    roc = roc_auc_score(y, preds)       # ROC AUC ê³„ì‚°\n",
    "    pr = average_precision_score(y, preds)  # PR AUC ê³„ì‚°\n",
    "    return roc, pr\n",
    "\n",
    "\n",
    "# âœ… TabNetClassifier ê¸°ë°˜ êµì°¨ê²€ì¦ í•¨ìˆ˜\n",
    "# ì§€ì •ëœ ìˆ˜ë™ ê°€ì¤‘ì¹˜(manual_weights)ì™€ TabNet í•˜ì´í¼íŒŒë¼ë¯¸í„°(tabnet_params)ë¥¼ ì‚¬ìš©í•˜ì—¬ Kê²¹ êµì°¨ê²€ì¦ ìˆ˜í–‰\n",
    "\n",
    "def cross_validate_tabnet_classifier(X, y,\n",
    "                                     manual_weights=None,\n",
    "                                     tabnet_params=None,\n",
    "                                     k=5,\n",
    "                                     max_epochs=200,\n",
    "                                     patience=30,\n",
    "                                     batch_size=512,\n",
    "                                     device_name='auto'):\n",
    "    \n",
    "    # Stratified K-Foldë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []  # ì ìˆ˜ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    # ê° foldì— ëŒ€í•´ ë°˜ë³µ ìˆ˜í–‰\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        # foldë§ˆë‹¤ ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ\n",
    "        clf = train_tabnet_classifier(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            manual_weights=manual_weights,\n",
    "            tabnet_params=tabnet_params,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        # ëª¨ë¸ í‰ê°€ ë° ì ìˆ˜ ì €ì¥\n",
    "        roc, pr = evaluate_tabnet_classifier(clf, X_val, y_val)\n",
    "        roc_list.append(roc)\n",
    "        pr_list.append(pr)\n",
    "\n",
    "    # í‰ê·  ë° í‘œì¤€í¸ì°¨ ì¶œë ¥\n",
    "    print(f\"ROC AUC (mean Â± std): {np.mean(roc_list):.4f} Â± {np.std(roc_list):.4f}\")\n",
    "    print(f\"PR  AUC (mean Â± std): {np.mean(pr_list):.4f} Â± {np.std(pr_list):.4f}\")\n",
    "    return roc_list, pr_list\n",
    "\n",
    "\n",
    "# âœ… TabNetClassifierìš© ëœë¤ ì„œì¹˜ í•¨ìˆ˜\n",
    "# PR AUCë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ì¤‘ ìƒìœ„ 5ê°œë¥¼ ì¶œë ¥í•˜ê³ , ìµœê³  ì¡°í•© ë°˜í™˜\n",
    "\n",
    "def random_search_tabnet(X, y, param_dist, n_iter=10, k=3,\n",
    "                          max_epochs=300, patience=50,\n",
    "                          batch_size=512, device_name='auto'):\n",
    "    results = []  # (ROC AUC, PR AUC, í•˜ì´í¼íŒŒë¼ë¯¸í„°) íŠœí”Œ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ëœë¤ ìƒ˜í”Œë§ ë°˜ë³µ\n",
    "    for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=None):\n",
    "        # n_d == n_aë¡œ ê°•ì œ ë™ê¸°í™”\n",
    "        if 'n_d' in params:\n",
    "            params['n_a'] = params['n_d']\n",
    "\n",
    "        print(f\"Testing params: {params}\")\n",
    "\n",
    "        # TabNetClassifierì— ì ìš©í•  íŒŒë¼ë¯¸í„°ë§Œ í•„í„°ë§\n",
    "        tabnet_keys = [\n",
    "            \"n_d\", \"n_a\", \"n_steps\", \"gamma\",\n",
    "            \"lambda_sparse\", \"optimizer_params\",\n",
    "            \"virtual_batch_size\", \"momentum\"\n",
    "        ]\n",
    "        tabnet_params = {k: params[k] for k in tabnet_keys if k in params}\n",
    "\n",
    "        # êµì°¨ê²€ì¦ ìˆ˜í–‰í•˜ì—¬ PR AUC ì¸¡ì •\n",
    "        roc_scores, pr_scores = cross_validate_tabnet_classifier(\n",
    "            X, y,\n",
    "            manual_weights=params.get(\"manual_weights\", None),\n",
    "            tabnet_params=tabnet_params,\n",
    "            k=k,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        mean_pr = np.mean(pr_scores)  # PR AUC í‰ê· \n",
    "        mean_roc = np.mean(roc_scores)  # ROC AUC í‰ê· \n",
    "        results.append((mean_pr, mean_roc, params))\n",
    "\n",
    "    # PR AUC ê¸°ì¤€ ìƒìœ„ 5ê°œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ì¶œë ¥\n",
    "    results.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_results = results[:5]\n",
    "\n",
    "    print(\"\\nTop 5 PR AUC results:\")\n",
    "    for i, (pr_score, roc_score, params) in enumerate(top_results, 1):\n",
    "        print(f\"{i}. ROC AUC = {roc_score:.4f}, PR AUC = {pr_score:.4f} with params: {params}\")\n",
    "\n",
    "    best_pr, best_roc, best_params = top_results[0]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96b4b96-1800-45e7-bf13-35d5498d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… TabNetClassifier ê¸°ë°˜ì˜ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ë“¤ (DataFrame ì¹œí™” ë²„ì „)\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# âœ… TabNetClassifier í•™ìŠµ í•¨ìˆ˜ (DataFrame ë²„ì „)\n",
    "def train_tabnet_classifier_df(X_train, y_train, X_val, y_val,\n",
    "                                manual_weights=None,\n",
    "                                tabnet_params=None,\n",
    "                                max_epochs=100, patience=10,\n",
    "                                batch_size=1024, device_name='auto'):\n",
    "    if tabnet_params is None:\n",
    "        tabnet_params = {}\n",
    "\n",
    "    # âœ… ì…ë ¥ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (DataFrame ìœ ì§€)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "\n",
    "    clf = TabNetClassifier(\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        device_name=device_name,\n",
    "        **tabnet_params\n",
    "    )\n",
    "\n",
    "    if manual_weights is not None:\n",
    "        clf.manual_weights = manual_weights\n",
    "\n",
    "    clf.fit(\n",
    "        X_train=X_train_scaled.values, y_train=y_train.values,\n",
    "        eval_set=[(X_val_scaled.values, y_val.values)],\n",
    "        eval_metric=['auc', 'logloss'],\n",
    "        max_epochs=max_epochs,\n",
    "        patience=patience,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return clf, scaler\n",
    "\n",
    "# âœ… TabNetClassifier í‰ê°€ í•¨ìˆ˜ (DataFrame ë²„ì „)\n",
    "def evaluate_tabnet_classifier_df(clf, X, y, scaler):\n",
    "    # ì…ë ¥ ë°ì´í„°ë¥¼ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë³€í™˜ (DataFrame ìœ ì§€)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    preds = clf.predict_proba(X_scaled.values)[:, 1]  # ê¸ì • í´ë˜ìŠ¤ í™•ë¥  ì˜ˆì¸¡\n",
    "    roc = roc_auc_score(y, preds)       # ROC AUC ê³„ì‚°\n",
    "    pr = average_precision_score(y, preds)  # PR AUC ê³„ì‚°\n",
    "    return roc, pr\n",
    "\n",
    "# âœ… êµì°¨ê²€ì¦ í•¨ìˆ˜\n",
    "\n",
    "def cross_validate_tabnet_classifier_df(X, y,\n",
    "                                        manual_weights=None,\n",
    "                                        tabnet_params=None,\n",
    "                                        k=5,\n",
    "                                        max_epochs=200,\n",
    "                                        patience=30,\n",
    "                                        batch_size=1024,\n",
    "                                        device_name='auto'):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X.values, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        clf, scaler = train_tabnet_classifier_df(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            manual_weights=manual_weights,\n",
    "            tabnet_params=tabnet_params,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        roc, pr = evaluate_tabnet_classifier_df(clf, X_val, y_val, scaler)\n",
    "        roc_list.append(roc)\n",
    "        pr_list.append(pr)\n",
    "\n",
    "    print(f\"ROC AUC (mean Â± std): {np.mean(roc_list):.4f} Â± {np.std(roc_list):.4f}\")\n",
    "    print(f\"PR  AUC (mean Â± std): {np.mean(pr_list):.4f} Â± {np.std(pr_list):.4f}\")\n",
    "    return roc_list, pr_list\n",
    "\n",
    "# âœ… ëœë¤ì„œì¹˜ í•¨ìˆ˜\n",
    "\n",
    "def random_search_tabnet_df(X, y, param_dist, n_iter=10, k=3,\n",
    "                             max_epochs=100, patience=10,\n",
    "                             batch_size=1024, device_name='auto'):\n",
    "    results = []\n",
    "\n",
    "    for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=None):\n",
    "        # n_d == n_aë¡œ ê°•ì œ ë™ê¸°í™”\n",
    "        if 'n_d' in params:\n",
    "            params['n_a'] = params['n_d']\n",
    "        print(f\"Testing params: {params}\")\n",
    "\n",
    "        tabnet_keys = [\n",
    "            \"n_d\", \"n_a\", \"n_steps\", \"gamma\",\n",
    "            \"lambda_sparse\", \"optimizer_params\",\n",
    "            \"virtual_batch_size\", \"momentum\"\n",
    "        ]\n",
    "        tabnet_params = {k: params[k] for k in tabnet_keys if k in params}\n",
    "\n",
    "        roc_scores, pr_scores = cross_validate_tabnet_classifier_df(\n",
    "            X, y,\n",
    "            manual_weights=params.get(\"manual_weights\", None),\n",
    "            tabnet_params=tabnet_params,\n",
    "            k=k,\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            device_name=device_name\n",
    "        )\n",
    "        mean_roc = np.mean(roc_scores)\n",
    "        mean_pr = np.mean(pr_scores)\n",
    "        results.append((mean_pr, mean_roc, params))\n",
    "\n",
    "    results.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_results = results[:5]\n",
    "\n",
    "    print(\"\\nTop 5 PR AUC results:\")\n",
    "    for i, (pr_score, roc_score, params) in enumerate(top_results, 1):\n",
    "        print(f\"{i}. ROC AUC = {roc_score:.4f}, PR AUC = {pr_score:.4f} with params: {params}\")\n",
    "\n",
    "    best_pr, best_roc, best_params = top_results[0]\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5cd951-2c7c-402c-9b10-eba3591a6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 1. ì‹œë“œ ê³ ì • í•¨ìˆ˜ ì •ì˜\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # multi-GPU ì‚¬ìš© ì‹œ\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# âœ… 2. ì‹œë“œ ê³ ì •\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775045b-6db3-43d9-b0fd-df90c0362ce4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# âœ… TabNet ì˜ˆì‹œ ì½”ë“œ (ì‘ë™ í™•ì¸ìš©)\n",
    "\n",
    "# âœ… 1. ë”ë¯¸ ë°ì´í„° ìƒì„± (ì´ì§„ ë¶„ë¥˜ìš©)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20,\n",
    "    n_informative=10, n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# âœ… 2. train/test ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# âœ… 3. TabNetClassifier ì´ˆê¸°í™” ë° í•™ìŠµ\n",
    "clf = TabNetClassifier(\n",
    "    seed=42,\n",
    "    verbose=0,\n",
    "    device_name='auto'  # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìë™ ê°ì§€\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# âœ… 4. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "preds_proba = clf.predict_proba(X_test)[:, 1]\n",
    "preds_label = clf.predict(X_test)\n",
    "\n",
    "# âœ… 5. ì„±ëŠ¥ ì¶œë ¥\n",
    "roc = roc_auc_score(y_test, preds_proba)\n",
    "acc = accuracy_score(y_test, preds_label)\n",
    "\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87fb7d04-3680-4d95-88bf-ba8db68617dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ë„ë¡œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "data = pd.read_csv('data/(ìµœì¢…)_ì„œìš¸ì—´ì„ _ê´‘ì§„ë„ë¡œ.csv')\n",
    "X = pd.get_dummies(data[['ë„ë¡œ ì¢…ë¥˜', 'ë„ë¡œí­', 'ê²½ì‚¬ê°', 'ìµœê·¼ì ‘_ì‹œì„¤ì˜_í‰ê· ê±°ë¦¬', 'ì¢…í•©_í‰ê· _ê¸°ì˜¨', 'ìƒí™œì¸êµ¬', 'ìµœê·¼ì ‘_ì‹œì„¤ë“¤_ìµœì†Œê±°ë¦¬', 'ìµœê·¼ì ‘_ì‹œì„¤ë“¤_ìµœëŒ€ê±°ë¦¬']])\n",
    "y = data['ì—´ì„ ']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "X = X.astype('float')\n",
    "# ğŸ’¡ ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ì•ˆ í•˜ë©´ batch_sizeê°€ ì „ì²´ì¸ ê²½ìš° ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e93aa2d-73bd-406a-9579-9888649a6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    # í‘œí˜„ ì°¨ì› (í‘œí˜„ë ¥ ì¦ê°€ì— ì˜í–¥ì„ ì¤Œ)\n",
    "    \"n_d\": 64,\n",
    "    \"n_a\": 64,  # ì¼ë°˜ì ìœ¼ë¡œ n_dì™€ ê°™ì€ ê°’ì„ ì‚¬ìš©\n",
    "    # ëª¨ë¸ ê¹Šì´ (ë” ê¹Šìœ¼ë©´ ë³µì¡ë„ ì¦ê°€, í•™ìŠµ ì‹œê°„ ì¦ê°€)\n",
    "    \"n_steps\": 3,\n",
    "    # í¬ì†Œì„± ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° (íŠ¹ì„± ì„ íƒì„ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ í• ì§€)\n",
    "    \"gamma\": 2.0,\n",
    "    \"lambda_sparse\": 0.15,\n",
    "    # ì˜µí‹°ë§ˆì´ì € í•™ìŠµë¥ \n",
    "    \"optimizer_params\": dict(lr=0.001)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef17e0fc-70e8-49a4-848d-f0618bf3f139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 500 with best_epoch = 474 and best_val_0_logloss = 0.17709\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC: 0.9402\n",
      "PR  AUC: 0.8579\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 190 and best_val_0_logloss = 0.21651\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 196 and best_val_0_logloss = 0.20004\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 149 and best_val_0_logloss = 0.23165\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 172 with best_epoch = 112 and best_val_0_logloss = 0.1998\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 200 with best_epoch = 185 and best_val_0_logloss = 0.21332\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean Â± std): 0.9198 Â± 0.0104\n",
      "PR  AUC (mean Â± std): 0.7933 Â± 0.0218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.917670902716915,\n",
       "  0.9325007721984339,\n",
       "  0.9088652093385974,\n",
       "  0.9312399473607254,\n",
       "  0.908533167617098],\n",
       " [0.7792528661717667,\n",
       "  0.819999157915361,\n",
       "  0.759417458367711,\n",
       "  0.8105622880393578,\n",
       "  0.7974581902997006])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… 3. TabNetClassifier ì´ˆê¸°í™” ë° í•™ìŠµ\n",
    "model, scaler = train_tabnet_classifier_df(X_train=X_train, y_train=y_train, X_val=X_test, y_val=y_test,patience=250, max_epochs=500, tabnet_params=param_dist)\n",
    "\n",
    "# âœ… 4. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "roc, pr = evaluate_tabnet_classifier_df(model, X_test, y_test, scaler)\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "print(f\"PR  AUC: {pr:.4f}\")\n",
    "\n",
    "cross_validate_tabnet_classifier_df(X_train, y_train, batch_size=1024, tabnet_params=param_dist, max_epochs=200, patience=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd010a1-25a5-4e6e-81f1-f5ec9f014783",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    # í‘œí˜„ ì°¨ì› (í‘œí˜„ë ¥ ì¦ê°€ì— ì˜í–¥ì„ ì¤Œ)\n",
    "    \"n_d\": [32, 64],\n",
    "    \"n_a\": [32, 64],  # ì¼ë°˜ì ìœ¼ë¡œ n_dì™€ ê°™ì€ ê°’ì„ ì‚¬ìš©\n",
    "\n",
    "    # ëª¨ë¸ ê¹Šì´ (ë” ê¹Šìœ¼ë©´ ë³µì¡ë„ ì¦ê°€, í•™ìŠµ ì‹œê°„ ì¦ê°€)\n",
    "    \"n_steps\": [3, 4, 5],\n",
    "\n",
    "    # í¬ì†Œì„± ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° (íŠ¹ì„± ì„ íƒì„ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ í• ì§€)\n",
    "    \"gamma\": [1.5, 1.7, 1.8, 2.0],\n",
    "    \"lambda_sparse\": [1e-2, 5e-2, 1e-1],\n",
    "\n",
    "    # ì˜µí‹°ë§ˆì´ì € í•™ìŠµë¥ \n",
    "    \"optimizer_params\": [\n",
    "        dict(lr=0.001),\n",
    "        dict(lr=0.005),\n",
    "        dict(lr=0.01)\n",
    "    ],\n",
    "\n",
    "    # # ê°€ìƒ ë°°ì¹˜ ì‚¬ì´ì¦ˆ (BN ì•ˆì •í™” ëª©ì )\n",
    "    # \"virtual_batch_size\": [128, 256],\n",
    "\n",
    "    # # Ghost BN ëª¨ë©˜í…€\n",
    "    # \"momentum\": [0.02, 0.05],\n",
    "\n",
    "    # í–¥í›„ í™•ì¥ìš© ìˆ˜ë™ íŠ¹ì„± ê°€ì¤‘ì¹˜\n",
    "    \"manual_weights\": [None]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a852732e-5d77-47aa-af07-ca302c544918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.5}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 163 and best_val_0_logloss = 0.20262\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 271 and best_val_0_logloss = 0.20769\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 191 and best_val_0_logloss = 0.20679\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean Â± std): 0.9238 Â± 0.0048\n",
      "PR  AUC (mean Â± std): 0.8092 Â± 0.0028\n",
      "Testing params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 195 and best_val_0_logloss = 0.20762\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 288 and best_val_0_logloss = 0.22474\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 291 and best_val_0_logloss = 0.1876\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean Â± std): 0.9197 Â± 0.0127\n",
      "PR  AUC (mean Â± std): 0.8026 Â± 0.0285\n",
      "Testing params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 5, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.8}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 299 and best_val_0_logloss = 0.24403\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 203 and best_val_0_logloss = 0.25728\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 277 and best_val_0_logloss = 0.26886\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean Â± std): 0.8914 Â± 0.0042\n",
      "PR  AUC (mean Â± std): 0.6919 Â± 0.0272\n",
      "Testing params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.1, 'gamma': 1.5}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 294 and best_val_0_logloss = 0.19203\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 222 and best_val_0_logloss = 0.22913\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 295 and best_val_0_logloss = 0.17797\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean Â± std): 0.9243 Â± 0.0134\n",
      "PR  AUC (mean Â± std): 0.8123 Â± 0.0417\n",
      "Testing params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 273 and best_val_0_logloss = 0.24458\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 299 and best_val_0_logloss = 0.25863\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 296 and best_val_0_logloss = 0.27468\n",
      "Best weights from best epoch are automatically used!\n",
      "ROC AUC (mean Â± std): 0.8926 Â± 0.0061\n",
      "PR  AUC (mean Â± std): 0.6901 Â± 0.0228\n",
      "\n",
      "Top 5 PR AUC results:\n",
      "1. ROC AUC = 0.9243, PR AUC = 0.8123 with params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.1, 'gamma': 1.5}\n",
      "2. ROC AUC = 0.9238, PR AUC = 0.8092 with params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.5}\n",
      "3. ROC AUC = 0.9197, PR AUC = 0.8026 with params: {'optimizer_params': {'lr': 0.01}, 'n_steps': 4, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n",
      "4. ROC AUC = 0.8914, PR AUC = 0.6919 with params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 5, 'n_d': 64, 'n_a': 64, 'manual_weights': None, 'lambda_sparse': 0.01, 'gamma': 1.8}\n",
      "5. ROC AUC = 0.8926, PR AUC = 0.6901 with params: {'optimizer_params': {'lr': 0.001}, 'n_steps': 3, 'n_d': 32, 'n_a': 32, 'manual_weights': None, 'lambda_sparse': 0.05, 'gamma': 1.7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optimizer_params': {'lr': 0.01},\n",
       " 'n_steps': 4,\n",
       " 'n_d': 32,\n",
       " 'n_a': 32,\n",
       " 'manual_weights': None,\n",
       " 'lambda_sparse': 0.1,\n",
       " 'gamma': 1.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_tabnet_df(X_train, y_train, param_dist=param_dist, n_iter=5, k=3, batch_size=X_train.shape[0], max_epochs=300, patience=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b012093-94a3-443a-a45a-33bc4911a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) \n",
    "X_train_scaled = scaler.fit_transform(X_train)   # fit + transform\n",
    "X_val_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469295c1-fc2a-486d-b303-82eca700028f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tabnet-39)",
   "language": "python",
   "name": "tabnet-39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
